{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97upigotLdg6"
      },
      "source": [
        "## Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G86PbWr6cC_D"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMZpvBWecC_K"
      },
      "source": [
        "## Loading and Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSW-17pxcC_K",
        "outputId": "58ce23ab-00f2-40c7-f57a-5b625806212d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iet6-60fcC_K"
      },
      "outputs": [],
      "source": [
        "ZERO = '/content/drive/MyDrive/Colab Notebooks/NeuralNetworksFromScratch/Image files/trainingSet/trainingSet/0'\n",
        "ONE =  '/content/drive/MyDrive/Colab Notebooks/NeuralNetworksFromScratch/Image files/trainingSet/trainingSet/1'\n",
        "TWO = '/content/drive/MyDrive/Colab Notebooks/NeuralNetworksFromScratch/Image files/trainingSet/trainingSet/2'\n",
        "THREE = '/content/drive/MyDrive/Colab Notebooks/NeuralNetworksFromScratch/Image files/trainingSet/trainingSet/3'\n",
        "FOUR = '/content/drive/MyDrive/Colab Notebooks/NeuralNetworksFromScratch/Image files/trainingSet/trainingSet/4'\n",
        "FIVE = '/content/drive/MyDrive/Colab Notebooks/NeuralNetworksFromScratch/Image files/trainingSet/trainingSet/5'\n",
        "SIX = '/content/drive/MyDrive/Colab Notebooks/NeuralNetworksFromScratch/Image files/trainingSet/trainingSet/6'\n",
        "SEVEN = '/content/drive/MyDrive/Colab Notebooks/NeuralNetworksFromScratch/Image files/trainingSet/trainingSet/7'\n",
        "EIGHT = '/content/drive/MyDrive/Colab Notebooks/NeuralNetworksFromScratch/Image files/trainingSet/trainingSet/8'\n",
        "NINE = '/content/drive/MyDrive/Colab Notebooks/NeuralNetworksFromScratch/Image files/trainingSet/trainingSet/9'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2J-yOa3tcC_K"
      },
      "outputs": [],
      "source": [
        "training_data = []\n",
        "validation_data = []\n",
        "testing_data = []\n",
        "number_of_zeros = 0\n",
        "paths_dict = {ZERO: 0, ONE: 1, TWO: 2, THREE: 3, FOUR: 4, FIVE: 5, SIX: 6, SEVEN: 7, EIGHT: 8, NINE: 9}\n",
        "paths_list = [ZERO, ONE, TWO, THREE, FOUR, FIVE, SIX, SEVEN, EIGHT, NINE]\n",
        "dataset_loaded = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81LEI81wcC_L",
        "outputId": "b10c69f5-7d59-45ae-b471-2f32bc71d380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▊      | 1600/4132 [00:10<00:17, 147.37it/s]\n",
            " 34%|███▍      | 1600/4684 [00:08<00:16, 184.33it/s]\n",
            " 38%|███▊      | 1600/4177 [00:08<00:13, 184.62it/s]\n",
            " 37%|███▋      | 1600/4351 [00:08<00:14, 188.18it/s]\n",
            " 39%|███▉      | 1600/4072 [00:08<00:12, 190.63it/s]\n",
            " 42%|████▏     | 1600/3795 [00:08<00:11, 194.93it/s]\n",
            " 39%|███▊      | 1600/4137 [00:08<00:13, 190.49it/s]\n",
            " 36%|███▋      | 1600/4401 [01:35<02:47, 16.71it/s] \n",
            " 39%|███▉      | 1600/4063 [01:19<02:02, 20.09it/s] \n",
            " 38%|███▊      | 1600/4188 [01:25<02:18, 18.75it/s] \n"
          ]
        }
      ],
      "source": [
        "if dataset_loaded is False:\n",
        "  for folder in paths_list:\n",
        "    image_count = 0\n",
        "    for image_path in tqdm(os.listdir(folder)):\n",
        "      if image_count < 1000:\n",
        "        if \"jpg\" in image_path:\n",
        "          path = os.path.join(folder, image_path)\n",
        "          image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "          if image is not None:\n",
        "            flattened_input = image.reshape(-1)\n",
        "            flattened_input = flattened_input/255\n",
        "            training_data.append([flattened_input, np.eye(10)[paths_dict[folder]]])\n",
        "            image_count += 1\n",
        "      elif (image_count >= 1000) and (image_count < 1200):\n",
        "        if \"jpg\" in image_path:\n",
        "          path = os.path.join(folder, image_path)\n",
        "          image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "          if image is not None:\n",
        "            flattened_input = image.reshape(-1)\n",
        "            flattened_input = flattened_input/255\n",
        "            validation_data.append([flattened_input, np.eye(10)[paths_dict[folder]]])\n",
        "            image_count += 1\n",
        "      elif (image_count >= 1200) and (image_count < 1600):\n",
        "        if \"jpg\" in image_path:\n",
        "          path = os.path.join(folder, image_path)\n",
        "          image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "          if image is not None:\n",
        "            flattened_input = image.reshape(-1)\n",
        "            flattened_input = flattened_input/255\n",
        "            testing_data.append([flattened_input, np.eye(10)[paths_dict[folder]]])\n",
        "            image_count += 1\n",
        "      else:\n",
        "        break\n",
        "dataset_loaded = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LirOsatJcC_L"
      },
      "outputs": [],
      "source": [
        "np.random.shuffle(training_data)\n",
        "np.random.shuffle(validation_data)\n",
        "np.random.shuffle(testing_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r1VuWAjcC_L",
        "outputId": "07156803-11d5-4fe4-a385-d8f111869224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "2000\n",
            "4000\n"
          ]
        }
      ],
      "source": [
        "print(len(training_data))\n",
        "print(len(validation_data))\n",
        "print(len(testing_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining a function to divide the dataset into batches"
      ],
      "metadata": {
        "id": "iHy1oVBW9JF2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "J6pNVmUZcC_L"
      },
      "outputs": [],
      "source": [
        "def mini_batch(dataset, batch_size):\n",
        "  batched_data = []\n",
        "  dataset_size = int(len(dataset)/batch_size)*batch_size\n",
        "  dataset = dataset[:dataset_size]\n",
        "  for i in range(0, dataset_size, batch_size):\n",
        "    batched_data.append(dataset[i:i+batch_size])\n",
        "  return batched_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making mini-batches out of the train set and separating the features and labels"
      ],
      "metadata": {
        "id": "baxA-Ay19NQD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RwK5NxZdcC_L"
      },
      "outputs": [],
      "source": [
        "batched_training_data = mini_batch(training_data, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bL8F5QJ5cC_L"
      },
      "outputs": [],
      "source": [
        "batched_features = []\n",
        "batched_labels = []\n",
        "\n",
        "for i in range(len(batched_training_data)):\n",
        "  features_list = []\n",
        "  labels_list = []\n",
        "  for j in range(64):\n",
        "    features_list.append(batched_training_data[i][j][0])\n",
        "    labels_list.append(batched_training_data[i][j][1])\n",
        "  batched_features.append(np.array(features_list))\n",
        "  batched_labels.append(np.array(labels_list))\n",
        "\n",
        "batched_features = np.array(batched_features)\n",
        "batched_labels = np.array(batched_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making mini-batches out of the validation set and separating the features and labels"
      ],
      "metadata": {
        "id": "GVJut1Tk9YGe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhE1nD59JbiZ",
        "outputId": "21d9fd40-7bb7-4cd4-9196-4db9ce3ad63c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "batched_validation_data = mini_batch(validation_data, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bi-BBUENJXJY"
      },
      "outputs": [],
      "source": [
        "validation_features = []\n",
        "validation_labels = []\n",
        "\n",
        "for i in range(len(batched_validation_data)):\n",
        "  features_list = []\n",
        "  labels_list = []\n",
        "  for j in range(64):\n",
        "    features_list.append(batched_validation_data[i][j][0])\n",
        "    labels_list.append(batched_validation_data[i][j][1])\n",
        "  validation_features.append(np.array(features_list))\n",
        "  validation_labels.append(np.array(labels_list))\n",
        "\n",
        "batched_validation_features = np.array(validation_features)\n",
        "batched_validation_labels = np.array(validation_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making mini-batches out of the test set and separating the features and labels"
      ],
      "metadata": {
        "id": "gizHuANj9grB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batched_testing_data = mini_batch(testing_data, 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7VfMvHFJ7cN",
        "outputId": "c986ea86-79d9-4712-83b0-2af73238336b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wK6ppvMDJ1C5"
      },
      "outputs": [],
      "source": [
        "testing_features = []\n",
        "testing_labels = []\n",
        "\n",
        "for i in range(len(batched_testing_data)):\n",
        "  features_list = []\n",
        "  labels_list = []\n",
        "  for j in range(64):\n",
        "    features_list.append(batched_testing_data[i][j][0])\n",
        "    labels_list.append(batched_testing_data[i][j][1])\n",
        "  testing_features.append(np.array(features_list))\n",
        "  testing_labels.append(np.array(labels_list))\n",
        "\n",
        "batched_testing_features = np.array(testing_features)\n",
        "batched_testing_labels = np.array(testing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY2L-CkrOau7"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the parameters of the model"
      ],
      "metadata": {
        "id": "czZoNkaP8aba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "id": "vVoeJNu8NtXd"
      },
      "outputs": [],
      "source": [
        "weights = [np.random.normal(0, 0.1, size=(784, 128)), np.random.normal(0, 0.1, size=(128, 10))]\n",
        "bias = [np.zeros([64, 128]), np.zeros([64, 10])]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Activation Functions "
      ],
      "metadata": {
        "id": "otSCKes38c3E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "id": "cHaf1TpRmcH_"
      },
      "outputs": [],
      "source": [
        "def relu(matrix):\n",
        "  return np.maximum(matrix, 0)\n",
        "\n",
        "def reluDerivative(x):\n",
        "  y = (x > 0) * 1\n",
        "  return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {
        "id": "3FMTPW6ORcs5"
      },
      "outputs": [],
      "source": [
        "def softmax(matrix):\n",
        "  softmax_matrix = np.zeros(matrix.shape)\n",
        "  for row_index in range(len(matrix)):\n",
        "    softmax_matrix[row_index] = (np.exp(matrix[row_index])/sum(np.exp(matrix[row_index])))\n",
        "    for element in np.exp(matrix[row_index]):\n",
        "      if element == np.inf:\n",
        "        print(matrix[row_index])\n",
        "  return softmax_matrix "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Cost Function"
      ],
      "metadata": {
        "id": "J_Hj8Koa8wKT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "id": "nve3W2PuTnCT"
      },
      "outputs": [],
      "source": [
        "def cost(output, labels):\n",
        "  loss_matrix = -np.mean(np.multiply(labels, np.log(output)), axis=1)\n",
        "  loss = (1/output.shape[0])*sum(loss_matrix)\n",
        "  return loss "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the parameters of the model to calculate the output through feedforward"
      ],
      "metadata": {
        "id": "s3jHGJbI8rG8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {
        "id": "2ubVtAsrnQFT"
      },
      "outputs": [],
      "source": [
        "def feedforward(input_matrix, weight_matrix, bias_matrix, activation_function):\n",
        "  z = np.matmul(input_matrix, weight_matrix) + bias_matrix\n",
        "  if activation_function == 'relu':\n",
        "    a = relu(z)\n",
        "    return a, z\n",
        "  elif activation_function == 'softmax':\n",
        "    a = softmax(z)\n",
        "    return a, z\n",
        "  else:\n",
        "    print(\"Invalid Activation Function.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "6ma1heYp87GS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {
        "id": "PpfNDV0wYL5U"
      },
      "outputs": [],
      "source": [
        "# r is the number of samples in each batch\n",
        "r = 64\n",
        "total_epochs = 200\n",
        "\n",
        "# The loss obtained frmo each version of the model as the model is trained over \n",
        "# a certain number of epochs is stored to be plotted later\n",
        "cost_func_graph = []\n",
        "validation_cost_func_graph = []\n",
        "def training():\n",
        "    for epoch in range(total_epochs):\n",
        "\n",
        "      # Checking the validation cost\n",
        "      valCostSum = 0\n",
        "      for batch_index in range(len(batched_validation_data)):\n",
        "        validation_batch = batched_validation_features[batch_index]\n",
        "        validation_labels = batched_validation_labels[batch_index]\n",
        "\n",
        "        output_1, logits_1 = feedforward(validation_batch, weights[0], bias[0], 'relu')\n",
        "        output_2, logits_2 = feedforward(output_1, weights[1], bias[1], 'softmax')\n",
        "\n",
        "        val_output= np.zeros_like(output_2)\n",
        "        val_output[np.arange(len(output_2)), output_2.argmax(1)] = 1\n",
        "\n",
        "        valCostSum = cost(output_2, validation_labels)\n",
        "\n",
        "      validation_cost = valCostSum/31\n",
        "      validation_cost_func_graph.append(validation_cost)\n",
        "\n",
        "\n",
        "      # Training\n",
        "      for batch_index in range(len(batched_training_data)):\n",
        "        batch = batched_features[batch_index]\n",
        "        labels = batched_labels[batch_index]\n",
        "\n",
        "        # FEEDFORWARD\n",
        "        first_layer_output, first_layer_logits = feedforward(batch, weights[0], bias[0], 'relu')\n",
        "        final_output, final_logits = feedforward(first_layer_output, weights[1], bias[1], 'softmax')\n",
        "\n",
        "        # BACKPROPAGATION\n",
        "        delta_weights = [np.zeros([784, 128]), np.zeros([128, 10])]\n",
        "        delta_bias = [np.zeros([r, 128]), np.zeros([r, 10])]\n",
        "\n",
        "        # Backpropagation through the last layer\n",
        "        # Backpropagation for weights\n",
        "        ones_matrix = np.ones([r, 10])\n",
        "        one_minus_final_output_times_labels = np.multiply((ones_matrix - final_output), labels)\n",
        "        one_minus_final_output_times_labels = one_minus_final_output_times_labels/r\n",
        "        first_layer_output_transpose = first_layer_output.transpose()\n",
        "        delta_weights[1] = -np.matmul(first_layer_output_transpose, one_minus_final_output_times_labels)\n",
        "        delta_weights[1] = delta_weights[1]/r\n",
        "        delta_weights[1] = delta_weights[1]*0.1\n",
        "        weights[1] -= delta_weights[1]\n",
        "\n",
        "        # Calculating the variation of the cost with respect to the input of the last layer\n",
        "        final_layer_weights_transpose = weights[1].transpose()\n",
        "        CVWFO = -np.matmul(one_minus_final_output_times_labels, final_layer_weights_transpose)\n",
        "\n",
        "        # Backpropgation for bias\n",
        "        delta_bias[1][0] = -np.mean(one_minus_final_output_times_labels, axis=0)\n",
        "        for i in range(r):\n",
        "          delta_bias[1][i] = delta_bias[1][0]\n",
        "        delta_bias[1] = delta_bias[1]/r\n",
        "        delta_bias[1] = delta_bias[1]*0.1\n",
        "        bias[1] -= delta_bias[1]\n",
        "\n",
        "        # Backpropagation through the first layer\n",
        "        # Backpropagation for weights\n",
        "        first_layer_logits_relu_derivative = reluDerivative(first_layer_logits)\n",
        "        first_layer_logits_relu_derivative_times_CVWFO = np.multiply(first_layer_logits_relu_derivative, CVWFO)\n",
        "        first_layer_logits_relu_derivative_times_CVWFO = first_layer_logits_relu_derivative_times_CVWFO/r\n",
        "        inputs_transpose = batch.transpose()\n",
        "        delta_weights[0] = np.matmul(inputs_transpose, first_layer_logits_relu_derivative_times_CVWFO)\n",
        "        delta_weights[0] = (delta_weights[0])/r\n",
        "        delta_weights[0] = delta_weights[0]*0.01\n",
        "        weights[0] -= delta_weights[0]\n",
        "\n",
        "\n",
        "        # Backpropagation for bias\n",
        "        delta_bias[0][0] = np.mean(first_layer_logits_relu_derivative_times_CVWFO, axis=0)\n",
        "        for i in range(r):\n",
        "          delta_bias[0][i] = delta_bias[0][0]\n",
        "        delta_bias[0] = delta_bias[0]/r\n",
        "        delta_bias[0] = delta_bias[0]*0.01\n",
        "        bias[1] -= delta_bias[1]\n",
        "\n",
        "      training_cost = cost(final_output, labels)\n",
        "      cost_func_graph.append(training_cost)\n",
        "\n",
        "      training_output = np.zeros_like(final_output)\n",
        "      training_output[np.arange(len(training_output)), training_output.argmax(1)] = 1\n",
        "\n",
        "      print(f\"Epoch : {epoch} - Training Cost : {training_cost} - Validation Cost : {validation_cost}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6k8LrvuEExQ",
        "outputId": "45c491d3-0d2d-4532-b13e-c6660a57c5f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0 - Training Cost : 0.25454782845583507 - Validation Cost : 0.0084765951082529\n",
            "Epoch : 1 - Training Cost : 0.24137332127241856 - Validation Cost : 0.008122618381294685\n",
            "Epoch : 2 - Training Cost : 0.22971876978981373 - Validation Cost : 0.007809911824995917\n",
            "Epoch : 3 - Training Cost : 0.21940785000134824 - Validation Cost : 0.0075306296381268635\n",
            "Epoch : 4 - Training Cost : 0.21022849651832545 - Validation Cost : 0.007276424400579294\n",
            "Epoch : 5 - Training Cost : 0.2019805065109606 - Validation Cost : 0.007040166584416051\n",
            "Epoch : 6 - Training Cost : 0.19450729500371447 - Validation Cost : 0.006817217999803138\n",
            "Epoch : 7 - Training Cost : 0.18769805869329734 - Validation Cost : 0.006605420674496548\n",
            "Epoch : 8 - Training Cost : 0.18147480591552395 - Validation Cost : 0.006404207088510341\n",
            "Epoch : 9 - Training Cost : 0.17577840732422687 - Validation Cost : 0.006213666190247766\n",
            "Epoch : 10 - Training Cost : 0.1705591958253402 - Validation Cost : 0.006033971367024494\n",
            "Epoch : 11 - Training Cost : 0.16577298752280323 - Validation Cost : 0.005865131027654299\n",
            "Epoch : 12 - Training Cost : 0.16137987999217107 - Validation Cost : 0.005706943603374149\n",
            "Epoch : 13 - Training Cost : 0.1573429500134016 - Validation Cost : 0.005559055923257627\n",
            "Epoch : 14 - Training Cost : 0.15362891647457044 - Validation Cost : 0.005420982827612552\n",
            "Epoch : 15 - Training Cost : 0.15020674037356546 - Validation Cost : 0.00529217421254641\n",
            "Epoch : 16 - Training Cost : 0.1470482029337844 - Validation Cost : 0.005172053660941397\n",
            "Epoch : 17 - Training Cost : 0.1441281214308254 - Validation Cost : 0.0050600154401164565\n",
            "Epoch : 18 - Training Cost : 0.14142376565335296 - Validation Cost : 0.0049554448446396645\n",
            "Epoch : 19 - Training Cost : 0.13891458865496623 - Validation Cost : 0.00485778667688413\n",
            "Epoch : 20 - Training Cost : 0.13658241365157053 - Validation Cost : 0.0047665058579912725\n",
            "Epoch : 21 - Training Cost : 0.13441023343852537 - Validation Cost : 0.004681074666703824\n",
            "Epoch : 22 - Training Cost : 0.13238343050590418 - Validation Cost : 0.0046010066788357866\n",
            "Epoch : 23 - Training Cost : 0.13048832058934612 - Validation Cost : 0.004525829274416994\n",
            "Epoch : 24 - Training Cost : 0.12871457958685836 - Validation Cost : 0.0044551422576719815\n",
            "Epoch : 25 - Training Cost : 0.1270518479330165 - Validation Cost : 0.004388586273810942\n",
            "Epoch : 26 - Training Cost : 0.1254903969327959 - Validation Cost : 0.004325794458542708\n",
            "Epoch : 27 - Training Cost : 0.12402219255868653 - Validation Cost : 0.004266450559594201\n",
            "Epoch : 28 - Training Cost : 0.12264049625619308 - Validation Cost : 0.004210294328778594\n",
            "Epoch : 29 - Training Cost : 0.1213380274459819 - Validation Cost : 0.0041570646384920884\n",
            "Epoch : 30 - Training Cost : 0.12010851602671527 - Validation Cost : 0.004106571739557974\n",
            "Epoch : 31 - Training Cost : 0.11894622461334627 - Validation Cost : 0.004058605666715228\n",
            "Epoch : 32 - Training Cost : 0.11784669981630984 - Validation Cost : 0.004012986124787599\n",
            "Epoch : 33 - Training Cost : 0.11680486760266194 - Validation Cost : 0.0039695232912777545\n",
            "Epoch : 34 - Training Cost : 0.1158163948687487 - Validation Cost : 0.003928059355710394\n",
            "Epoch : 35 - Training Cost : 0.11487802399394349 - Validation Cost : 0.003888455230247579\n",
            "Epoch : 36 - Training Cost : 0.11398742488095182 - Validation Cost : 0.003850570171035825\n",
            "Epoch : 37 - Training Cost : 0.11314166759290543 - Validation Cost : 0.003814295642038118\n",
            "Epoch : 38 - Training Cost : 0.11233680124993069 - Validation Cost : 0.003779539733269961\n",
            "Epoch : 39 - Training Cost : 0.11157133814380646 - Validation Cost : 0.003746210934378517\n",
            "Epoch : 40 - Training Cost : 0.11084167478536242 - Validation Cost : 0.0037142121805556457\n",
            "Epoch : 41 - Training Cost : 0.11014576007672734 - Validation Cost : 0.0036834691194530308\n",
            "Epoch : 42 - Training Cost : 0.10948225229211514 - Validation Cost : 0.003653909495405826\n",
            "Epoch : 43 - Training Cost : 0.10884792868827754 - Validation Cost : 0.0036254593647234825\n",
            "Epoch : 44 - Training Cost : 0.10823931950371661 - Validation Cost : 0.003598087139812243\n",
            "Epoch : 45 - Training Cost : 0.10765773771939126 - Validation Cost : 0.003571737503131453\n",
            "Epoch : 46 - Training Cost : 0.10710074230690192 - Validation Cost : 0.003546371699481359\n",
            "Epoch : 47 - Training Cost : 0.10656750175001961 - Validation Cost : 0.0035219264629406345\n",
            "Epoch : 48 - Training Cost : 0.10605655504754617 - Validation Cost : 0.003498413560934514\n",
            "Epoch : 49 - Training Cost : 0.10556615038896688 - Validation Cost : 0.0034757516648241137\n",
            "Epoch : 50 - Training Cost : 0.10509340990201967 - Validation Cost : 0.0034538646332108133\n",
            "Epoch : 51 - Training Cost : 0.10464110465096133 - Validation Cost : 0.0034326811418873677\n",
            "Epoch : 52 - Training Cost : 0.10420828603718098 - Validation Cost : 0.003412142137756918\n",
            "Epoch : 53 - Training Cost : 0.10379302055680077 - Validation Cost : 0.0033923019763098497\n",
            "Epoch : 54 - Training Cost : 0.10339462575434812 - Validation Cost : 0.003373106072078887\n",
            "Epoch : 55 - Training Cost : 0.10301177549885847 - Validation Cost : 0.0033545174932564\n",
            "Epoch : 56 - Training Cost : 0.10264390219209198 - Validation Cost : 0.0033364854206476935\n",
            "Epoch : 57 - Training Cost : 0.10229027264513374 - Validation Cost : 0.0033189941900029743\n",
            "Epoch : 58 - Training Cost : 0.10195003403571003 - Validation Cost : 0.003302019725857201\n",
            "Epoch : 59 - Training Cost : 0.1016225075368625 - Validation Cost : 0.003285564415231243\n",
            "Epoch : 60 - Training Cost : 0.10130741397228912 - Validation Cost : 0.003269593485064395\n",
            "Epoch : 61 - Training Cost : 0.10100358575233596 - Validation Cost : 0.0032540864107703377\n",
            "Epoch : 62 - Training Cost : 0.10071128610133072 - Validation Cost : 0.0032390185606153018\n",
            "Epoch : 63 - Training Cost : 0.10042895407348876 - Validation Cost : 0.0032243511993656077\n",
            "Epoch : 64 - Training Cost : 0.10015531851660209 - Validation Cost : 0.003210114493471143\n",
            "Epoch : 65 - Training Cost : 0.09989193194539839 - Validation Cost : 0.00319617219990708\n",
            "Epoch : 66 - Training Cost : 0.09963763689929864 - Validation Cost : 0.0031826077115117224\n",
            "Epoch : 67 - Training Cost : 0.099392727592041 - Validation Cost : 0.0031693897020429445\n",
            "Epoch : 68 - Training Cost : 0.09915571409501693 - Validation Cost : 0.003156524034416289\n",
            "Epoch : 69 - Training Cost : 0.0989257683431223 - Validation Cost : 0.0031439558495415863\n",
            "Epoch : 70 - Training Cost : 0.09870418692557233 - Validation Cost : 0.0031317612594606655\n",
            "Epoch : 71 - Training Cost : 0.09849049808563104 - Validation Cost : 0.0031199147030138556\n",
            "Epoch : 72 - Training Cost : 0.09828624668474634 - Validation Cost : 0.0031083822309540725\n",
            "Epoch : 73 - Training Cost : 0.0980923001149817 - Validation Cost : 0.003097155324087032\n",
            "Epoch : 74 - Training Cost : 0.09790569614364605 - Validation Cost : 0.0030861663924670016\n",
            "Epoch : 75 - Training Cost : 0.09772653098329638 - Validation Cost : 0.003075444311796124\n",
            "Epoch : 76 - Training Cost : 0.0975551982300191 - Validation Cost : 0.0030650359678045438\n",
            "Epoch : 77 - Training Cost : 0.09739039398046885 - Validation Cost : 0.0030548385345489618\n",
            "Epoch : 78 - Training Cost : 0.09723121599487908 - Validation Cost : 0.0030448135229645566\n",
            "Epoch : 79 - Training Cost : 0.09707755213462062 - Validation Cost : 0.0030351075144361877\n",
            "Epoch : 80 - Training Cost : 0.09693136924931078 - Validation Cost : 0.003025593682797178\n",
            "Epoch : 81 - Training Cost : 0.09678989792968656 - Validation Cost : 0.0030163037967380502\n",
            "Epoch : 82 - Training Cost : 0.09665333481420593 - Validation Cost : 0.0030072518356163993\n",
            "Epoch : 83 - Training Cost : 0.09652429502843349 - Validation Cost : 0.002998422258294808\n",
            "Epoch : 84 - Training Cost : 0.09640076850624454 - Validation Cost : 0.002989813065054682\n",
            "Epoch : 85 - Training Cost : 0.09628239692242038 - Validation Cost : 0.002981427350197348\n",
            "Epoch : 86 - Training Cost : 0.09617004995603802 - Validation Cost : 0.0029732196054689107\n",
            "Epoch : 87 - Training Cost : 0.09606216498271938 - Validation Cost : 0.0029652066299981953\n",
            "Epoch : 88 - Training Cost : 0.09595736308175254 - Validation Cost : 0.0029574002555683705\n",
            "Epoch : 89 - Training Cost : 0.09585598387037106 - Validation Cost : 0.0029497698736141117\n",
            "Epoch : 90 - Training Cost : 0.09575807850722033 - Validation Cost : 0.002942449556882606\n",
            "Epoch : 91 - Training Cost : 0.0956630650025342 - Validation Cost : 0.002935369935899051\n",
            "Epoch : 92 - Training Cost : 0.09556952815049327 - Validation Cost : 0.002928476474704817\n",
            "Epoch : 93 - Training Cost : 0.09547773243282547 - Validation Cost : 0.0029219609510793363\n",
            "Epoch : 94 - Training Cost : 0.09538935752875635 - Validation Cost : 0.0029156283425474197\n",
            "Epoch : 95 - Training Cost : 0.0953060067087059 - Validation Cost : 0.002909478927084558\n",
            "Epoch : 96 - Training Cost : 0.0952266924768396 - Validation Cost : 0.0029034859662525002\n",
            "Epoch : 97 - Training Cost : 0.0951505039782695 - Validation Cost : 0.002897668943606411\n",
            "Epoch : 98 - Training Cost : 0.09507756571963133 - Validation Cost : 0.0028920352812881215\n",
            "Epoch : 99 - Training Cost : 0.0950070302990768 - Validation Cost : 0.002886587856790522\n",
            "Epoch : 100 - Training Cost : 0.09493912171648046 - Validation Cost : 0.002881336649861148\n",
            "Epoch : 101 - Training Cost : 0.09487397987552018 - Validation Cost : 0.0028762162229800476\n",
            "Epoch : 102 - Training Cost : 0.09481151312838912 - Validation Cost : 0.002871334822193459\n",
            "Epoch : 103 - Training Cost : 0.09475214382802606 - Validation Cost : 0.0028666195876086687\n",
            "Epoch : 104 - Training Cost : 0.09469531277444145 - Validation Cost : 0.0028620465959884175\n",
            "Epoch : 105 - Training Cost : 0.09463345460146165 - Validation Cost : 0.002857619750917265\n",
            "Epoch : 106 - Training Cost : 0.09457326000001683 - Validation Cost : 0.0028532933432191226\n",
            "Epoch : 107 - Training Cost : 0.09451663745633747 - Validation Cost : 0.002848961499493549\n",
            "Epoch : 108 - Training Cost : 0.09445907701176502 - Validation Cost : 0.002844469520871433\n",
            "Epoch : 109 - Training Cost : 0.0944032669839047 - Validation Cost : 0.0028401375980454807\n",
            "Epoch : 110 - Training Cost : 0.09434961813737124 - Validation Cost : 0.002835832381219384\n",
            "Epoch : 111 - Training Cost : 0.09429873398763544 - Validation Cost : 0.002831753387430756\n",
            "Epoch : 112 - Training Cost : 0.09425275216246397 - Validation Cost : 0.002827761596232239\n",
            "Epoch : 113 - Training Cost : 0.09420868717196762 - Validation Cost : 0.0028239267792360377\n",
            "Epoch : 114 - Training Cost : 0.09416607281756686 - Validation Cost : 0.002820206993079871\n",
            "Epoch : 115 - Training Cost : 0.09412442700873039 - Validation Cost : 0.002816783946128063\n",
            "Epoch : 116 - Training Cost : 0.09408742148644858 - Validation Cost : 0.002813499775967814\n",
            "Epoch : 117 - Training Cost : 0.09406028431157952 - Validation Cost : 0.0028102852108447597\n",
            "Epoch : 118 - Training Cost : 0.09403587858551689 - Validation Cost : 0.002807304606754302\n",
            "Epoch : 119 - Training Cost : 0.09401396055421615 - Validation Cost : 0.002804629778694686\n",
            "Epoch : 120 - Training Cost : 0.09399340216023515 - Validation Cost : 0.0028020574338285787\n",
            "Epoch : 121 - Training Cost : 0.09398094890906453 - Validation Cost : 0.0027995872793295457\n",
            "Epoch : 122 - Training Cost : 0.0939683360949834 - Validation Cost : 0.002797159629662633\n",
            "Epoch : 123 - Training Cost : 0.09395849136473562 - Validation Cost : 0.0027948384412392674\n",
            "Epoch : 124 - Training Cost : 0.09395507855404094 - Validation Cost : 0.0027926978291823077\n",
            "Epoch : 125 - Training Cost : 0.0939537093057073 - Validation Cost : 0.00279061908204619\n",
            "Epoch : 126 - Training Cost : 0.09395496449493256 - Validation Cost : 0.0027885636894823865\n",
            "Epoch : 127 - Training Cost : 0.09395684348814268 - Validation Cost : 0.002786452581048504\n",
            "Epoch : 128 - Training Cost : 0.0939597790811071 - Validation Cost : 0.0027844093602696104\n",
            "Epoch : 129 - Training Cost : 0.09396615773647576 - Validation Cost : 0.00278247363622225\n",
            "Epoch : 130 - Training Cost : 0.09397580421652076 - Validation Cost : 0.002780607865751705\n",
            "Epoch : 131 - Training Cost : 0.09399011350522653 - Validation Cost : 0.0027788940331240886\n",
            "Epoch : 132 - Training Cost : 0.09400717028600143 - Validation Cost : 0.0027772996361656306\n",
            "Epoch : 133 - Training Cost : 0.09402524265971568 - Validation Cost : 0.0027758369693211323\n",
            "Epoch : 134 - Training Cost : 0.09404489368818306 - Validation Cost : 0.0027746430422058697\n",
            "Epoch : 135 - Training Cost : 0.09406640309506292 - Validation Cost : 0.002773555329930657\n",
            "Epoch : 136 - Training Cost : 0.09409091200844062 - Validation Cost : 0.002772425396726677\n",
            "Epoch : 137 - Training Cost : 0.09411838122478439 - Validation Cost : 0.0027714338131616108\n",
            "Epoch : 138 - Training Cost : 0.09415077221054256 - Validation Cost : 0.002770529410112171\n",
            "Epoch : 139 - Training Cost : 0.0941840721490836 - Validation Cost : 0.0027697025288288667\n",
            "Epoch : 140 - Training Cost : 0.09422072775646391 - Validation Cost : 0.0027689647016319605\n",
            "Epoch : 141 - Training Cost : 0.09426164041429272 - Validation Cost : 0.0027682331822610038\n",
            "Epoch : 142 - Training Cost : 0.09430864738463261 - Validation Cost : 0.0027675596724935727\n",
            "Epoch : 143 - Training Cost : 0.09435879094094199 - Validation Cost : 0.0027669572813491276\n",
            "Epoch : 144 - Training Cost : 0.09440853137585059 - Validation Cost : 0.002766502380942445\n",
            "Epoch : 145 - Training Cost : 0.09445918773207578 - Validation Cost : 0.002766214978764027\n",
            "Epoch : 146 - Training Cost : 0.09451074632577583 - Validation Cost : 0.002765995033678875\n",
            "Epoch : 147 - Training Cost : 0.09456223255120252 - Validation Cost : 0.002765720143038528\n",
            "Epoch : 148 - Training Cost : 0.0946142349388944 - Validation Cost : 0.0027655603438198916\n",
            "Epoch : 149 - Training Cost : 0.09466646511000164 - Validation Cost : 0.0027655288959474627\n",
            "Epoch : 150 - Training Cost : 0.0947198718761257 - Validation Cost : 0.0027655834067798254\n",
            "Epoch : 151 - Training Cost : 0.09477367968018915 - Validation Cost : 0.0027656926192848497\n",
            "Epoch : 152 - Training Cost : 0.09482901129621686 - Validation Cost : 0.0027659092785373546\n",
            "Epoch : 153 - Training Cost : 0.09488566250846549 - Validation Cost : 0.0027662587442840144\n",
            "Epoch : 154 - Training Cost : 0.09494395553883597 - Validation Cost : 0.002766657002368804\n",
            "Epoch : 155 - Training Cost : 0.0950034029538997 - Validation Cost : 0.0027671095981288613\n",
            "Epoch : 156 - Training Cost : 0.09506358524528834 - Validation Cost : 0.002767692682104716\n",
            "Epoch : 157 - Training Cost : 0.09512284232130762 - Validation Cost : 0.0027683381221643836\n",
            "Epoch : 158 - Training Cost : 0.09518247416768434 - Validation Cost : 0.0027690416095465225\n",
            "Epoch : 159 - Training Cost : 0.09524310403430879 - Validation Cost : 0.002769796613234886\n",
            "Epoch : 160 - Training Cost : 0.09530361469005093 - Validation Cost : 0.0027705336991973926\n",
            "Epoch : 161 - Training Cost : 0.09536455750610967 - Validation Cost : 0.0027712879981359193\n",
            "Epoch : 162 - Training Cost : 0.09542537624534221 - Validation Cost : 0.0027721323511378554\n",
            "Epoch : 163 - Training Cost : 0.09548765309019552 - Validation Cost : 0.0027730584146013625\n",
            "Epoch : 164 - Training Cost : 0.09555247321228534 - Validation Cost : 0.0027740614770745977\n",
            "Epoch : 165 - Training Cost : 0.09561726063324893 - Validation Cost : 0.0027751432013766422\n",
            "Epoch : 166 - Training Cost : 0.09568220003645071 - Validation Cost : 0.00277624646508246\n",
            "Epoch : 167 - Training Cost : 0.09575104356017176 - Validation Cost : 0.00277741407372489\n",
            "Epoch : 168 - Training Cost : 0.09582640126647922 - Validation Cost : 0.002778660559789091\n",
            "Epoch : 169 - Training Cost : 0.09590188664612499 - Validation Cost : 0.0027799122042174657\n",
            "Epoch : 170 - Training Cost : 0.09597415275966567 - Validation Cost : 0.0027812233815727705\n",
            "Epoch : 171 - Training Cost : 0.09605056826975487 - Validation Cost : 0.0027824436283199\n",
            "Epoch : 172 - Training Cost : 0.09612775498234238 - Validation Cost : 0.0027833955709428834\n",
            "Epoch : 173 - Training Cost : 0.09620627574335339 - Validation Cost : 0.002784357624821511\n",
            "Epoch : 174 - Training Cost : 0.096287734430602 - Validation Cost : 0.002785334773391087\n",
            "Epoch : 175 - Training Cost : 0.09636735023082324 - Validation Cost : 0.0027862863950247597\n",
            "Epoch : 176 - Training Cost : 0.09645032402846881 - Validation Cost : 0.0027872364607734565\n",
            "Epoch : 177 - Training Cost : 0.096539415494731 - Validation Cost : 0.0027882679716590506\n",
            "Epoch : 178 - Training Cost : 0.09663091920304423 - Validation Cost : 0.002789395083414717\n",
            "Epoch : 179 - Training Cost : 0.09672186783874703 - Validation Cost : 0.002790567005921094\n",
            "Epoch : 180 - Training Cost : 0.09681661505705978 - Validation Cost : 0.0027917560219577415\n",
            "Epoch : 181 - Training Cost : 0.09691358373746777 - Validation Cost : 0.002792977898113478\n",
            "Epoch : 182 - Training Cost : 0.09701131605779381 - Validation Cost : 0.00279411191482135\n",
            "Epoch : 183 - Training Cost : 0.0971108636549731 - Validation Cost : 0.002795431872026685\n",
            "Epoch : 184 - Training Cost : 0.09720991657419224 - Validation Cost : 0.0027968227856907417\n",
            "Epoch : 185 - Training Cost : 0.09730932608509678 - Validation Cost : 0.0027982564337932386\n",
            "Epoch : 186 - Training Cost : 0.09740957227436657 - Validation Cost : 0.002799750621106458\n",
            "Epoch : 187 - Training Cost : 0.09751046410328344 - Validation Cost : 0.002801324444550707\n",
            "Epoch : 188 - Training Cost : 0.09761204283479018 - Validation Cost : 0.0028029443032620543\n",
            "Epoch : 189 - Training Cost : 0.09771432812474912 - Validation Cost : 0.0028045579597466034\n",
            "Epoch : 190 - Training Cost : 0.0978174491776893 - Validation Cost : 0.0028062016804944593\n",
            "Epoch : 191 - Training Cost : 0.09792163138700032 - Validation Cost : 0.002807971712663197\n",
            "Epoch : 192 - Training Cost : 0.09802800336657079 - Validation Cost : 0.002809821085453859\n",
            "Epoch : 193 - Training Cost : 0.09813833598385242 - Validation Cost : 0.002811684858610678\n",
            "Epoch : 194 - Training Cost : 0.0982509362804297 - Validation Cost : 0.002813592569401124\n",
            "Epoch : 195 - Training Cost : 0.09836420445069496 - Validation Cost : 0.002815535272019828\n",
            "Epoch : 196 - Training Cost : 0.09847470543392495 - Validation Cost : 0.0028174973809602494\n",
            "Epoch : 197 - Training Cost : 0.09857414904751183 - Validation Cost : 0.0028195677946615126\n",
            "Epoch : 198 - Training Cost : 0.09867044737317103 - Validation Cost : 0.0028216777287045822\n",
            "Epoch : 199 - Training Cost : 0.09876711366761017 - Validation Cost : 0.0028237862130397564\n"
          ]
        }
      ],
      "source": [
        "training()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model"
      ],
      "metadata": {
        "id": "S-jbV60W6Bw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting the graph of *Cost VS Epochs* for training and validation"
      ],
      "metadata": {
        "id": "gao-9oER7gOU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "NIm1f5egwK7h",
        "outputId": "c657e7cd-b206-44f4-ecc3-f48fd5c0d617"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "epochs=  200\n",
        "if len(cost_func_graph) == 0:\n",
        "  print(\"The data has not been trained yet\")\n",
        "else:\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot([i for i in range(epochs)],cost_func_graph)\n",
        "  plt.plot([i for i in range(epochs)],validation_cost_func_graph)\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Cost_Function\")\n",
        "  plt.legend(['Training Loss', 'Validation Loss'])\n",
        "  plt.grid(True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the model using the test set"
      ],
      "metadata": {
        "id": "ImK-1nvu7S5-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fim1XQUWpvoX",
        "outputId": "12f638c5-71b1-4363-9798-baf548a05dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy : 77.85\n",
            "Test Accuracy : 75.85\n"
          ]
        }
      ],
      "source": [
        "test_count = 0\n",
        "for batch_index in range(len(batched_testing_data)):\n",
        "  batch = batched_testing_features[batch_index]\n",
        "  label = batched_testing_labels[batch_index]\n",
        "\n",
        "  first_layer_output, first_layer_logits = feedforward(batch, weights[0], bias[0], 'relu')\n",
        "  final_output, final_logits = feedforward(first_layer_output, weights[1], bias[1], 'softmax')\n",
        "\n",
        "  one_hot_output= np.zeros_like(final_output)\n",
        "  one_hot_output[np.arange(len(final_output)), final_output.argmax(1)] = 1\n",
        "\n",
        "  count_for_batch = 0\n",
        "  for i in range(len(label)):\n",
        "    if (label[i] == one_hot_output[i]).all():\n",
        "      count_for_batch += 1\n",
        "  \n",
        "  test_count += count_for_batch\n",
        "\n",
        "train_count = 0\n",
        "for batch_index in range(len(batched_training_data)):\n",
        "  batch = batched_features[batch_index]\n",
        "  label = batched_labels[batch_index]\n",
        "\n",
        "  first_layer_output, first_layer_logits = feedforward(batch, weights[0], bias[0], 'relu')\n",
        "  final_output, final_logits = feedforward(first_layer_output, weights[1], bias[1], 'softmax')\n",
        "\n",
        "  one_hot_output= np.zeros_like(final_output)\n",
        "  one_hot_output[np.arange(len(final_output)), final_output.argmax(1)] = 1\n",
        "\n",
        "  count_for_batch = 0\n",
        "  for i in range(len(label)):\n",
        "    if (label[i] == one_hot_output[i]).all():\n",
        "      count_for_batch += 1\n",
        "  \n",
        "  train_count += count_for_batch\n",
        "\n",
        "print(f\"Training Accuracy : {(train_count/10000)*100}\")\n",
        "print(f\"Test Accuracy : {(test_count/4000)*100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Taking a sample image and passing it through the model"
      ],
      "metadata": {
        "id": "dgnMvlrY7Wkm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "id": "94v5WWOKgV2z"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/NeuralNetworksFromScratch/Image files/trainingSample/img_602.jpg', cv2.IMREAD_GRAYSCALE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "oBEvm2_pvFLu",
        "outputId": "f86f4dd5-655c-4c65-b487-1c7a8524b2bd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABqUlEQVR4nL2SMWsUQRiGn/lmdnYnd3uXxAghGDkixEIEQQg2doIWgWhl6R+wUCzs7LQRsUmlptVCtLC1CvgLLCxENCh6wkWS3J53t3e3Oxa7Hu79AJ9uvpdv3u97Z6BkERwGmNMAAqCYojxWj8gAy4gKkQUChHDeMIMYcDgRwEBtRo6WNzZfHuY+935nlYpnbG9tne3/3HvTfdc+8aujs0rjFZ9sXzyGOGdDoWqrtvqPGgRKEAtNpvsAeDd61QvH9Vz0GHqmInK52ckjEpOPvVLZhGLqgrXB+wOOQETbSVrUpuLn5mA/dN0gJR8Xcf177adz19JD0noERNZXpg1aH7t3FxBM3SrFDHL8gc9unipPbiY9Flee+YMnlyDUZS0EwxyBxjhYf/E1ebwGEpbR6OkLSJPw5P3B8MZfz1oAOGuwMQhozvzYv81yoWodKUCBEohFaHXvxWW2PhtqHB7ROSrJ1cbzuJc0yk5syNLqkkHD+oWHu/3O0wWiIr5oklLbvn70vR1jT2uSO7sfGgwBlMlzifpXz7c259tvf6/svf7yjWhoZ37f/+MPUpB3jVG2fdoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F4A4CFDF050>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {
        "id": "YI0y93HjvHsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b79609c8-5a17-4b87-d27b-3a3d338cc1a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "flattened_image = np.array([image.reshape(-1)])/255\n",
        "\n",
        "test_first_layer_output, test_first_layer_logit = feedforward(flattened_image, weights[0], bias[0][0], 'relu')\n",
        "test_output, test_logit = feedforward(test_first_layer_output, weights[1], bias[1][0], 'softmax')\n",
        "\n",
        "one_hot_test_output= np.zeros_like(test_output)\n",
        "one_hot_test_output[np.arange(len(test_output)), test_output.argmax(1)] = 1\n",
        "\n",
        "print(one_hot_test_output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NeuralNetwork.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}